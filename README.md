# MUSCLE SYNERGY IDENTIFICATION

#### _Musheng He_
**March ~ June; Oct ~ Dec 2020**

- [Method](#method)
  - [Hardware Setup](#hardware-setup)
  - [Experimental Procedures](#experimental-rocedures)

- [Demo and Result](#demo)

- [Software Structure & Included packages](#packages-breakdown)

- [Implementation Instruction](#implementation-instruction)


This project aims to identify how muscles are synergistically activated at the arm during a multi-joint task.

#### Motivation

While seemingly simple, a motor task, such as retrieving an object from a high shelf, is very complicated. To achieve this task, movement-related signals are generated from the motor cortex of our brain and relayed to muscle fibers via motor neurons. In turn, muscles contract and the arm is raised and extended. There are more than 600 muscles in our body. Instead of controlling each muscle individually, our brain is thought to recruit these muscles in set groups. The activation of muscles in this grouped manner is termed muscle synergies and is part of a hierarchical control strategy. Activation of muscle synergies, rather than individual muscles, allows for a simplified control of oneâ€™s limb. In this work, the focus is on muscle activation at the arm. Specifically, the goal is to determine how muscles concurrently activate when an individual abducts at the shoulder and flexes at the elbow. As such, we can determine normal muscle activation patterns in a population that is neurologically and orthopaedically intact.

## Method

#### Hardware Setup

<img src="src/readme/setup.png" width="850">

The experimental setup, as shown in Figure 3, was comprised of a custom mechatronic system, a monitor, speakers, and Biodex chair. The system acquires torque data from a six-degree-of-freedom load cell. The acquired data, in conjunction with a biomechanical model, indicate the extent to which the participant flexes about the testing elbow and abducts about the shoulder. In addition, the system quantifies muscle activity using eight surface electromyography (sEMG) electrodes (sEMG1: biceps, sEMG2: triceps lateral, sEMG3: anterior deltoid, sEMG4: medial deltoid, sEMG5: posterior deltoid, sEMG6: pectoralis major, sEMG7: lower trapezius, and sEMG8: middle trapezius). The sEMG signals indicate the electrical activity within each of the eight testing muscles. A DAQ card acquires data from these sensors, and a Matlab program streams the data. Data is collected at 1kHz.

#### System Pipeline

<img src="journal_media/visual_pipeline.png" width="850">

The system acquires torque data indicating the extent to which the participant is flexing and extending about each elbow joint through two torque sensors. We used a DAQ card for data acquisition. A python script streams the sensory data at 1000Hz and passes signals to a callback function. The callback function utilizes the linear equation resulted from the [calibration](calibration/README.md) process to convert a voltage signal to the actual torque generated by the participant. A zeroing function can also be called to remove an offset in the voltage signal. The perceptual testing tasks use the results from the maximum voluntary torque test (maximum torque), as well as the real-time torque to determine the audiovisual feedback. The system renders the visual interface at 27Hz and records data at 1000Hz. 

## Demo and Result

- One can find a demo video at [here](https://youtu.be/ntOk0ySuN0E)
  
- Data recorded for further research in the format of  ` | Right Arm Torque | Left Arm Torque | Activity | Time Stamp | `
 <img src="journal_media/result_sample.png" width="700">

## Packages Breakdown

#### NIstreamer

- This is a Python library to stream data from the DAQ card channels at a desired frequency
- Signals from the DAQ card can be further proceeded by calling callback functions
- Artificial data streaming is available in the package without connecting to a DAQ card 

#### ni_stream.py

- The script serves as a callback function of the `NIstreamer` package
- The script calls a maximum voluntary torque test first to obtain offset and maximum torque data for the perceptual testing tasks.
- The script listens to a flag message from interfaces and triggers the recorder to write data in files with a desired frequency
- All interfaces are rendered at 27Hz

#### max_test.py
- This script creates an interface and provides audiovisual feedback to the participant for a maximum torque test
- This script returns the bias of the raw signal and the maximum torque generated by the participant's reference arm
-  <img src="journal_media/mvt_test.png" width="800">

#### arm_game.py
- This script creates an interface and provides audiovisual feedback to the participant for perceptual testing tasks
- The participant is asked to generate a torque larger than 40% of their maximum torque by the reference arm to remove the dirt on a picture (Phase 1)
- The participant is asked to use the indicative arm to generate a torque that is the same strength of the torque generated in Phase 1 without audiovisual feedback 
-  <img src="journal_media/game.png" width="800">

## Implementation Instruction

- Change file names you would like to save in `ni_stream.py`

~~~
python ni_stream.py
~~~


#### Change Interfaces

To add more pictures for the perceptual testing tasks:
-  add an image to the directory: ` armproj_ws\img\ `
-  append the new image name to the `showpic` variable of the `showpic_generator` class in `arm_game.py`

#### Test environment

Hardware:

- DAQ ##
- Torque sensor ##

Software:
- Windows Machine
- Python 3.6

Package Requirement:
- pygame (python)
- nidaqmx (python)